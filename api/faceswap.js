export default async function handler(req, res) {
    // CORS í—¤ë” ì„¤ì •
    res.setHeader('Access-Control-Allow-Origin', '*');
    res.setHeader('Access-Control-Allow-Methods', 'GET, POST, OPTIONS');
    res.setHeader('Access-Control-Allow-Headers', 'Content-Type, Authorization');

    // OPTIONS ìš”ì²­ (CORS preflight) ì²˜ë¦¬
    if (req.method === 'OPTIONS') {
        res.status(200).end();
        return;
    }

    // POST ìš”ì²­: ì–¼êµ´ í•©ì„±
    if (req.method === 'POST') {
        try {
            const { apiKey, personImage, adImage } = req.body;

            console.log('ğŸ­ Gemini ì–¼êµ´ í•©ì„± ì‹œì‘...');

            // Base64ì—ì„œ data:image/... í—¤ë” ì œê±°
            const personImageData = personImage.split(',')[1];
            const adImageData = adImage.split(',')[1];

            // Gemini API ìš”ì²­ êµ¬ì„±
            const requestBody = {
                contents: [
                    {
                        parts: [
                            {
                                inline_data: {
                                    mime_type: "image/jpeg",
                                    data: personImageData
                                }
                            },
                            {
                                inline_data: {
                                    mime_type: "image/jpeg",
                                    data: adImageData
                                }
                            },
                            {
                                text: "Use the SECOND uploaded image (or frame) as the base and final output.\n\nDo not generate a new scene and do not blend or merge the two images.\n\nKeep the base image exactly the same in background, body, pose, clothing, framing, and lighting.\n\nUse the FIRST uploaded image only as a facial reference.\n\nRecreate the face of the person in the base image so that it closely resembles the facial features of the person in the reference image.\n\nBlend the adjusted face naturally to match skin tone, lighting, angle, and perspective.\n\nKeep the result subtle, realistic, and consistent."
                            }
                        ]
                    }
                ],
                generationConfig: {
                    response_modalities: ["IMAGE", "TEXT"],
                    temperature: 0.7
                }
            };

            console.log('ğŸ“¤ Gemini API í˜¸ì¶œ ì¤‘...');

            // Gemini API í˜¸ì¶œ
            const GEMINI_API_ENDPOINT = 'https://generativelanguage.googleapis.com/v1beta/models/nano-banana-pro-preview:generateContent';
            const apiUrl = `${GEMINI_API_ENDPOINT}?key=${apiKey}`;

            const response = await fetch(apiUrl, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify(requestBody)
            });

            if (!response.ok) {
                const errorText = await response.text();
                console.error('âŒ Gemini API ì˜¤ë¥˜:', errorText);
                throw new Error(`Gemini API ì˜¤ë¥˜: ${response.status} ${response.statusText}`);
            }

            const result = await response.json();
            console.log('âœ… ì‘ë‹µ ë°›ìŒ');
            console.log('ì‘ë‹µ êµ¬ì¡°:', JSON.stringify(result, null, 2).substring(0, 500));

            // ì´ë¯¸ì§€ ì¶”ì¶œ
            let imageData = null;

            // finishReason ì²´í¬
            if (result.candidates && result.candidates[0]) {
                const finishReason = result.candidates[0].finishReason;
                console.log(`Finish Reason: ${finishReason}`);

                if (finishReason === 'OTHER' || finishReason === 'SAFETY') {
                    console.error('âŒ ëª¨ë¸ì´ ì‘ì—…ì„ ê±°ë¶€í–ˆìŠµë‹ˆë‹¤.');
                    console.error('ì „ì²´ ì‘ë‹µ:', JSON.stringify(result, null, 2));
                    throw new Error(`ë‚˜ë…¸ë°”ë‚˜ë‚˜ê°€ ì´ë¯¸ì§€ ìƒì„±ì„ ê±°ë¶€í–ˆìŠµë‹ˆë‹¤. Reason: ${finishReason}\n\nì´ ëª¨ë¸ì€ ì–¼êµ´ í•©ì„±(face swap)ì„ ì§€ì›í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.`);
                }
            }

            if (result.candidates && result.candidates[0] && result.candidates[0].content) {
                const parts = result.candidates[0].content.parts;

                if (!parts || parts.length === 0) {
                    console.error('âŒ content.partsê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.');
                    throw new Error('ì‘ë‹µì— partsê°€ ì—†ìŠµë‹ˆë‹¤');
                }

                console.log(`Parts ìˆ˜: ${parts.length}`);

                for (let i = 0; i < parts.length; i++) {
                    const part = parts[i];
                    console.log(`Part ${i}:`, Object.keys(part));

                    if (part.inline_data && part.inline_data.data) {
                        imageData = part.inline_data.data;
                        console.log(`âœ… Part ${i}ì—ì„œ ì´ë¯¸ì§€ ë°œê²¬! í¬ê¸°: ${imageData.length} bytes`);
                        break;
                    } else if (part.inlineData && part.inlineData.data) {
                        // camelCase ì‹œë„
                        imageData = part.inlineData.data;
                        console.log(`âœ… Part ${i}ì—ì„œ ì´ë¯¸ì§€ ë°œê²¬! (camelCase) í¬ê¸°: ${imageData.length} bytes`);
                        break;
                    }
                }
            }

            if (!imageData) {
                console.error('âŒ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ. ì „ì²´ ì‘ë‹µ:', JSON.stringify(result, null, 2));
                throw new Error('ì‘ë‹µì— ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤');
            }

            console.log('âœ… ì–¼êµ´ í•©ì„± ì™„ë£Œ!');

            res.status(200).json({
                success: true,
                image: `data:image/jpeg;base64,${imageData}`
            });

        } catch (error) {
            console.error('âŒ Error:', error.message);
            res.status(500).json({
                error: error.message
            });
        }
    } else {
        res.status(404).end('Not Found');
    }
}
